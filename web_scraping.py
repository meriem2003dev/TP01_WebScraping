# -*- coding: utf-8 -*-
"""web scraping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NAplWbmoGUyuJiqXFHu2PUwoNrmeenfK
"""

import requests
from bs4 import BeautifulSoup
import csv
from urllib.parse import urljoin
from google.colab import files

base_url = "https://books.toscrape.com/"

all_data = []
report_data = []

# 1) استخراج كل الأقسام من الصفحة الرئيسية
response = requests.get(base_url)
soup = BeautifulSoup(response.text, "html.parser")

categories = soup.find("ul", class_="nav nav-list").find_all("a")
categories = categories[1:]  # نتجاهل "Books" العامة

for cat in categories:
    category_name = cat.text.strip()
    category_url = urljoin(base_url, cat["href"])
    page_url = category_url

    books_count = 0
    pages_count = 0

    while True:
        response = requests.get(page_url)
        soup = BeautifulSoup(response.text, "html.parser")

        books = soup.find_all("article", class_="product_pod")
        pages_count += 1

        for book in books:
            title = book.h3.a["title"].strip()
            price = book.find("p", class_="price_color").text.strip()
            availability = book.find("p", class_="instock availability").text.strip()
            star_rating = book.p["class"][1]
            link = urljoin(page_url, book.h3.a["href"])

            all_data.append([category_name, title, price, availability, star_rating, link])
            books_count += 1

        # تحقق من وجود صفحة تالية
        next_btn = soup.find("li", class_="next")
        if next_btn:
            page_url = urljoin(page_url, next_btn.a["href"])
        else:
            break

    # أضف تقرير القسم
    report_data.append([category_name, books_count, pages_count])

# 2) حفظ ملف الكتب
books_file = "books_all_categories.csv"
with open(books_file, "w", newline="", encoding="utf-8-sig") as f:
    writer = csv.writer(f)
    writer.writerow(["Category", "Title", "Price", "Availability", "Star Rating", "Link"])
    writer.writerows(all_data)

# 3) حفظ ملف التقرير
report_file = "report.csv"
with open(report_file, "w", newline="", encoding="utf-8-sig") as f:
    writer = csv.writer(f)
    writer.writerow(["Category", "Books Count", "Pages Count"])
    writer.writerows(report_data)

print(f"✅ تم استخراج {len(all_data)} كتاب من {len(categories)} قسم")
print(f"📊 تم حفظ تقرير بعدد الكتب والصفحات في {report_file}")

# 4) تنزيل الملفات
files.download(books_file)
files.download(report_file)